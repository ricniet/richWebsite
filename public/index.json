[{"authors":null,"categories":["Tutorials","IRT"],"content":"I’ve spent considerable time developing JAGS/Stan code for fitting Bayesian IRT models. Understanding (let alone resolving) identification constraints has to be one of the most frustrating stages in the workflow. I think this is largely because constraints are already configured in the software we use to implement IRT analyses, so there’s just little reason to know the details! But for those of you who’ve fit latent variable models as Bayesian hierarchical models, you’ll know that understanding why such constraints are necessary, what options are available for model identification, and what their implications are for parameter interpretation can be really confusing.\nEven if you haven’t had to manually identify an IRT model before, it’s worth gaining intuition for it for at least 3 reasons:\nIt’s good to understand the defaults that a particular software/package provides, especially when making comparisons; It’s really helpful (and more important!) when you move to more complex models, such as explanatory or multidimensional IRT models; Latent variable models are inherently ambiguous, and identifying the metric on which parameters lie is a great exercise in becoming more comfortable with them.  In the first of (at least) two posts, I’m going to cover identification for a few of the more common IRT models. I’ll touch on constraints conceptually, but the real goal is to show you different ways of identifying IRT models in JAGS. I’ll focus on a few things with each example:\n Why constraints are necessary Different options for setting constraints Why we might (not) want to use a given set of constraints  Before diving in, it’s important to stress that identification is a property of the likelihood model, and thus, despite this post focusing on a Bayesian approach, it applies to frequentist methods as well.\nIRT Models for Binary Responses I. Rasch Model Let’s start with the simplest of IRT models. Letting \\(i\\) index individuals, and \\(j\\) index items, the Rasch model specifies the log-odds of a correct respone as the difference between an individual’s latent trait \\(\\theta_i\\) and item’s difficulty \\(\\beta_j\\). Let’s denote this difference \\(\\eta_{ij}\\):\n\\[ \\text{logit}\\big\\{p\\big(y_{ij} = 1 | \\Theta\\big)\\big\\} = \\theta_i - \\beta_j = \\eta_{ij}.\\]\nIs this model identified? The answer, of course, is no. The issue here is one that plagues all latent variable models—there is no inherent metric when we’re measuring unobserved variables, and so identifying a unique solution (i.e., obtaining parameter estimates) is impossible without first imposing a scale via constraints.\nThe issue is made evident when we consider the difference \\(\\eta_{ij}\\). Note that an endless number of solutions for \\(\\theta_i\\) and \\(\\beta_j\\) result in the same \\(\\eta_{ij}\\) (and by extension, likelihood). In the literature, this is often referred to as additive aliasing—adding the same constant to both \\(\\theta_i\\) and \\(\\beta_j\\) results in the same likelihood.\nTo make this really clear, suppose the “true” value of \\(\\eta_{11}\\) is \\(2\\). Well, setting \\(\\theta_1 = 3\\) and \\(\\beta_1 = 1\\) results in \\(\\eta_{11}=3 - 1 =2\\). But setting \\(\\theta_1=102\\) and \\(\\beta_1=100\\) also leads to \\(\\eta_{11} = 102-100=2\\). And for that matter, \\(\\eta_{11} = -3 - -5 = 2\\), and \\(\\eta_{11} = 2.3 - 0.3 = 2\\), and \\(\\eta_{11} = 3,222 - 3,000 = 2\\), and on we go on an endless quest to find a unique solution to an impossible mathematical problem.\n How do we identify this model? Because we’re interested in the relative difference between the latent trait and item difficulty, what we need is an anchoring point that will impose a metric and allow a unique solution to be found. There are many options for constraining the model, but I’ll focus on those most common in the psychometric literature:\nConstraining the mean and variance of the latent trait distribution, such that \\(\\theta_i \\sim \\mathcal{N}\\big(0, 1\\big)\\) for all \\(i\\) Constraining the mean of the item difficulties    II. Two-Parameter Logistic (2PL) Model \\[ \\text{logit}\\big\\{p\\big(y_{ij} = 1 | \\Theta\\big)\\big\\} = \\alpha_j\\big(\\theta_i - \\beta_j\\big) = \\eta_{ij}.\\]\n  IRT Models for Multinomial/Ordinal Responses Graded Response Model   ","date":1540684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540684800,"objectID":"47079014a2ff6b269f0c2004e8cc8a40","permalink":"/post/gaining-intuition-for-idenitification-constraints-in-bayesian-irt-models-part-i/","publishdate":"2018-10-28T00:00:00Z","relpermalink":"/post/gaining-intuition-for-idenitification-constraints-in-bayesian-irt-models-part-i/","section":"post","summary":"I’ve spent considerable time developing JAGS/Stan code for fitting Bayesian IRT models. Understanding (let alone resolving) identification constraints has to be one of the most frustrating stages in the workflow. I think this is largely because constraints are already configured in the software we use to implement IRT analyses, so there’s just little reason to know the details! But for those of you who’ve fit latent variable models as Bayesian hierarchical models, you’ll know that understanding why such constraints are necessary, what options are available for model identification, and what their implications are for parameter interpretation can be really confusing.","tags":["IRT","Tutorials","JAGS","R","Bayesian"],"title":"Gaining Intuition for Idenitification Constraints in Bayesian IRT Models: Part I","type":"post"},{"authors":null,"categories":null,"content":"I\u0026rsquo;ve spent considerable time developing JAGS/Stan code for fitting Bayesian IRT models. Understanding (let alone resolving) identification constraints has to be one of the most frustrating stages in the workflow. I think this is largely because constraints are already configured in the software we use to implement these models, so there\u0026rsquo;s just little reason to know the details! For those of us who work within a Bayesian framework, however, when it comes time to identify our model, it\u0026rsquo;s an inevitable trip to Google, and/or trial-and-error until we hope that our solutions worked.\nWe\u0026rsquo;ll start off with a simple Rasch model:\n$$ \\text{logit}\\Big(p\\big(y_{ij} = 1 \\big)\\Big) = \\theta_i - \\beta_j, $$\nwhich specifies the log-odds of a correct response for individual $i$ to binary item $j$ as the difference between their latent trait $\\theta_i$ and the difficulty of the item $\\beta_j$.\n","date":1536469200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536469200,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00-05:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"I\u0026rsquo;ve spent considerable time developing JAGS/Stan code for fitting Bayesian IRT models. Understanding (let alone resolving) identification constraints has to be one of the most frustrating stages in the workflow. I think this is largely because constraints are already configured in the software we use to implement these models, so there\u0026rsquo;s just little reason to know the details! For those of us who work within a Bayesian framework, however, when it comes time to identify our model, it\u0026rsquo;s an inevitable trip to Google, and/or trial-and-error until we hope that our solutions worked.","tags":null,"title":"Gaining Intuition for Identification Constraints in Bayesian IRT Models: Part I","type":"docs"},{"authors":[],"categories":null,"content":"Click on the Slides button above to view the built-in slides feature.\n Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483250400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483250400,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00-06:00","relpermalink":"/talk/example/","section":"talk","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":" Overview I\u0026rsquo;ve spent the better part of the last four years developing extensions to the hierarchical rater model (HRM), a latent variable modeling framework for the analysis of ratings data. In conjunction with Drs. Jodi Casabianca (Educational Testing Services, previously UT-Austin) and Brian Junker (Carnegie Mellon), this work has focused on developing theory, generating code for fitting Bayesian models, empirically testing these methods via Monte Carlo simulations, and disseminating the work through research articles and conference workshops. Keep reading to learn a bit more about the HRM, and the work I\u0026rsquo;m completing as part of my dissertation.\nHierarchical Rater Models Ratings are ubiquitous in psychological measurement\u0026mdash;performance appraisals in the industry rely on ratings collected from supervisors, therapists complete observational inventories to measure psychological traits, and essays from standardized tests are scored by raters trained on rating rubrics. From a measurement perspective, ratings are fundamentally flawed because they rely on subjective judgement. Idiosyncratic rater behavior introduces a form of measurement error, collectively called rater effects, that compromises the integrity of final scores used to describe the subject of those ratings. This is clearly problematic, given that assessments are designed to be fair, and final scores are often tied to high-stakes decisions.\nThe HRM framework was developed as a way to simultaneously describe individual rater behavior and provide measurement of individuals\u0026rsquo; psychological traits while correcting for rater effects. Besides providing more accurate and reliable measurement, by capturing rater behavior, it encourages ongoing assessment of raters\u0026rsquo; performance, which can be used to inform future rater trainings.\nThe HRM is a latent variable model composed of two separate modeling stages, which highlight the hierarchical structure of the rating process. The first stage is a signal detection model for observed ratings $x$ that produces as its output a measure of rater severity/leniency error, rater variability, as well as an ideal score $\\xi$ (the score the individual would have received from a perfect rater with no bias). The second stage is an item response theory (IRT) model, which takes these ideal ratings (corrected for rater effects), and produces estimates of the latent trait of interest $\\theta$ (e.g., depression, writing procifiency).\nExtensions of this basic model have been made to accommodate multidimensional structure in rating instruments, time series and longitudinal ratings, and inclusion of covariates of the rating process.\nMy Research My work on the HRM includes the development of the HRM for multidimensional rating rubrics (paper just submitted!), as well as the evaluation of the HRM for rater covariates (my dissertation).\nIf you\u0026rsquo;re interested in more on the mechanics of the HRM, stay tuned for upcoming tutorials.\n","date":1461733200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461733200,"objectID":"840a5607cf0c6809be660526d6934c31","permalink":"/project/research/","publishdate":"2016-04-27T00:00:00-05:00","relpermalink":"/project/research/","section":"project","summary":"Dissertation Research","tags":["Research","Psychometrics","Measurement"],"title":"Research","type":"project"},{"authors":["GA Cushen"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1441083600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441083600,"objectID":"d77fa4a74076ffcd7ca6c21cfc27a4b2","permalink":"/publication/person-re-id/","publishdate":"2015-09-01T00:00:00-05:00","relpermalink":"/publication/person-re-id/","section":"publication","summary":"Person re-identification is a critical security task for recognizing a person across spatially disjoint sensors. Previous work can be computationally intensive and is mainly based on low-level cues extracted from RGB data and implemented on a PC for a fixed sensor network (such as traditional CCTV). We present a practical and efficient framework for mobile devices (such as smart phones and robots) where high-level semantic soft biometrics are extracted from RGB and depth data. By combining these cues, our approach attempts to provide robustness to noise, illumination, and minor variations in clothing. This mobile approach may be particularly useful for the identification of persons in areas ill-served by fixed sensors or for tasks where the sensor position and direction need to dynamically adapt to a target. Results on the BIWI dataset are preliminary but encouraging. Further evaluation and demonstration of the system will be available on our website.","tags":[],"title":"A Person Re-Identification System For Mobile Devices","type":"publication"},{"authors":["GA Cushen","MS Nixon"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1372654800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372654800,"objectID":"2b4d919e3cf73dfcd0063c88fe01cb00","permalink":"/publication/clothing-search/","publishdate":"2013-07-01T00:00:00-05:00","relpermalink":"/publication/clothing-search/","section":"publication","summary":"We present a mobile visual clothing search system whereby a smart phone user can either choose a social networking photo or take a new photo of a person wearing clothing of interest and search for similar clothing in a retail database. From the query image, the person is detected, clothing is segmented, and clothing features are extracted and quantized. The information is sent from the phone client to a server, where the feature vector of the query image is used to retrieve similar clothing products from online databases. The phone's GPS location is used to re-rank results by retail store location. State of the art work focuses primarily on the recognition of a diverse range of clothing offline and pays little attention to practical applications. Evaluated on a challenging dataset, the system is relatively fast and achieves promising results.","tags":[],"title":"Mobile visual clothing search","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]